import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.datasets import load_iris
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
import io
import numpy as np

def preprocesamiento_iris():


    # ============================================
    # 1Ô∏è‚É£ CARGA DEL DATASET
    # ============================================
    st.subheader("1Ô∏è‚É£ Cargar dataset desde sklearn")
    iris = load_iris()
    st.write("Dataset cargado desde `sklearn.datasets`.")

    # ============================================
    # 2Ô∏è‚É£ CONVERTIR A DATAFRAME
    # ============================================
    st.subheader("2Ô∏è‚É£ Convertir a DataFrame y agregar nombres de columnas")
    df = pd.DataFrame(iris.data, columns=iris.feature_names)
    df['target'] = iris.target
    st.write("**Primeras filas del dataset:**")
    st.dataframe(df.head())

    # Informaci√≥n inicial
    st.write("**Informaci√≥n general del dataset:**")
    buffer = io.StringIO()
    df.info(buf=buffer)
    st.text(buffer.getvalue())

    st.write("**Descripci√≥n estad√≠stica inicial:**")
    st.dataframe(df.describe())

    st.write("**Valores nulos por columna:**")
    st.dataframe(df.isnull().sum())

    # ============================================
    # 3Ô∏è‚É£ ESTANDARIZACI√ìN
    # ============================================
    st.subheader("3Ô∏è‚É£ Estandarizaci√≥n de variables num√©ricas")
    features = iris.feature_names
    scaler = StandardScaler()
    df[features] = scaler.fit_transform(df[features])

    st.write("**Primeras filas despu√©s de estandarizar:**")
    st.dataframe(df.head())

    st.write("**Descripci√≥n estad√≠stica despu√©s del escalado:**")
    st.dataframe(df[features].describe())

    # ============================================
    # 4Ô∏è‚É£ DIVISI√ìN EN ENTRENAMIENTO Y PRUEBA
    # ============================================
    st.subheader("4Ô∏è‚É£ Divisi√≥n en entrenamiento y prueba")
    X = df[features].values
    y = df['target'].values
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

    st.write(f"üîπ X_train: {X_train.shape}")
    st.write(f"üîπ X_test: {X_test.shape}")
    st.write(f"üîπ y_train: {y_train.shape}")
    st.write(f"üîπ y_test: {y_test.shape}")

    st.write("**Primeras filas de X_train:**")
    st.dataframe(pd.DataFrame(X_train, columns=features).head())

    # ============================================
    # 5Ô∏è‚É£ GR√ÅFICO DE DISPERSI√ìN
    # ============================================
    st.subheader("5Ô∏è‚É£ Gr√°fico de dispersi√≥n: Sepal length vs Petal length")
    plt.figure(figsize=(8,6))
    for target, color, label in zip([0,1,2], ['r','g','b'], iris.target_names):
        plt.scatter(
            df.loc[df['target']==target, 'sepal length (cm)'],
            df.loc[df['target']==target, 'petal length (cm)'],
            c=color,
            label=label
        )
    plt.xlabel("Sepal length (estandarizado)")
    plt.ylabel("Petal length (estandarizado)")
    plt.title("Distribuci√≥n de Sepal length vs Petal length por clase")
    plt.legend()
    st.pyplot(plt)

    # ============================================
    # 6Ô∏è‚É£ CONCLUSI√ìN
    # ============================================
    st.subheader("6Ô∏è‚É£ Conclusi√≥n del preprocesamiento")
    st.write("""
    ‚úîÔ∏è Cargamos el dataset Iris  
    ‚úîÔ∏è Convertimos a DataFrame y agregamos nombres de columnas  
    ‚úîÔ∏è Estandarizamos las variables num√©ricas  
    ‚úîÔ∏è Dividimos en entrenamiento y prueba  
    ‚úîÔ∏è Graficamos la relaci√≥n entre Sepal length y Petal length diferenciada por clase
    """)
    st.success("üéØ Preprocesamiento completado con √©xito.")

    return X_train, X_test, y_train, y_test, df

import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.datasets import load_iris
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
import io
import numpy as np

def preprocesamiento_iris():
    st.title("ğŸŒ¸ Ejercicio 3: Preprocesamiento del Dataset Iris (Paso a paso)")

    # ============================================
    # 1ï¸âƒ£ CARGA DEL DATASET
    # ============================================
    st.subheader("1ï¸âƒ£ Cargar dataset desde sklearn")
    iris = load_iris()
    st.write("Dataset cargado desde `sklearn.datasets`.")

    # ============================================
    # 2ï¸âƒ£ CONVERTIR A DATAFRAME
    # ============================================
    st.subheader("2ï¸âƒ£ Convertir a DataFrame y agregar nombres de columnas")
    df = pd.DataFrame(iris.data, columns=iris.feature_names)
    df['target'] = iris.target
    st.write("**Primeras filas del dataset:**")
    st.dataframe(df.head())

    # InformaciÃ³n inicial
    st.write("**InformaciÃ³n general del dataset:**")
    buffer = io.StringIO()
    df.info(buf=buffer)
    st.text(buffer.getvalue())

    st.write("**DescripciÃ³n estadÃ­stica inicial:**")
    st.dataframe(df.describe())

    st.write("**Valores nulos por columna:**")
    st.dataframe(df.isnull().sum())

    # ============================================
    # 3ï¸âƒ£ ESTANDARIZACIÃ“N
    # ============================================
    st.subheader("3ï¸âƒ£ EstandarizaciÃ³n de variables numÃ©ricas")
    features = iris.feature_names
    scaler = StandardScaler()
    df[features] = scaler.fit_transform(df[features])

    st.write("**Primeras filas despuÃ©s de estandarizar:**")
    st.dataframe(df.head())

    st.write("**DescripciÃ³n estadÃ­stica despuÃ©s del escalado:**")
    st.dataframe(df[features].describe())

    # ============================================
    # 4ï¸âƒ£ DIVISIÃ“N EN ENTRENAMIENTO Y PRUEBA
    # ============================================
    st.subheader("4ï¸âƒ£ DivisiÃ³n en entrenamiento y prueba")
    X = df[features].values
    y = df['target'].values
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

    st.write(f"ğŸ”¹ X_train: {X_train.shape}")
    st.write(f"ğŸ”¹ X_test: {X_test.shape}")
    st.write(f"ğŸ”¹ y_train: {y_train.shape}")
    st.write(f"ğŸ”¹ y_test: {y_test.shape}")

    st.write("**Primeras filas de X_train:**")
    st.dataframe(pd.DataFrame(X_train, columns=features).head())

    # ============================================
    # 5ï¸âƒ£ GRÃFICO DE DISPERSIÃ“N
    # ============================================
    st.subheader("5ï¸âƒ£ GrÃ¡fico de dispersiÃ³n: Sepal length vs Petal length")
    plt.figure(figsize=(8,6))
    for target, color, label in zip([0,1,2], ['r','g','b'], iris.target_names):
        plt.scatter(
            df.loc[df['target']==target, 'sepal length (cm)'],
            df.loc[df['target']==target, 'petal length (cm)'],
            c=color,
            label=label
        )
    plt.xlabel("Sepal length (estandarizado)")
    plt.ylabel("Petal length (estandarizado)")
    plt.title("DistribuciÃ³n de Sepal length vs Petal length por clase")
    plt.legend()
    st.pyplot(plt)

    # ============================================
    # 6ï¸âƒ£ CONCLUSIÃ“N
    # ============================================
    st.subheader("6ï¸âƒ£ ConclusiÃ³n del preprocesamiento")
    st.write("""
    âœ”ï¸ Cargamos el dataset Iris  
    âœ”ï¸ Convertimos a DataFrame y agregamos nombres de columnas  
    âœ”ï¸ Estandarizamos las variables numÃ©ricas  
    âœ”ï¸ Dividimos en entrenamiento y prueba  
    âœ”ï¸ Graficamos la relaciÃ³n entre Sepal length y Petal length diferenciada por clase
    """)
    st.success("ğŸ¯ Preprocesamiento completado con Ã©xito.")

    return X_train, X_test, y_train, y_test, df
